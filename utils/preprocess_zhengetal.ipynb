{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3602f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import scipy.io\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from scipy.signal import butter, lfilter\n",
    "import pickle\n",
    "\n",
    "def butter_bandpass(lowcut, highcut, fs, order=5):\n",
    "    nyq = 0.5 * fs\n",
    "    low = lowcut / nyq\n",
    "    high = highcut / nyq\n",
    "    b, a = butter(order, [low, high], btype='band')\n",
    "    return b, a\n",
    "\n",
    "\n",
    "def butter_bandpass_filter(data, lowcut, highcut, fs, order=5):\n",
    "    b, a = butter_bandpass(lowcut, highcut, fs, order=order)\n",
    "    y = lfilter(b, a, data)\n",
    "    return y\n",
    "\n",
    "def butter_lowpass(lowcut, fs, order=5):\n",
    "    nyq = 0.5 * fs\n",
    "    low = lowcut / nyq\n",
    "    b, a = butter(order, low, btype='low')\n",
    "    return b, a\n",
    "\n",
    "\n",
    "def butter_lowpass_filter(data, lowcut, fs, order=5):\n",
    "    b, a = butter_lowpass(lowcut, fs, order=order)\n",
    "    y = lfilter(b, a, data)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a943af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = \"[path to Zheng et al. dataset downloaded from PhysioNet]/WFDBRecords\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a89e772c",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = []\n",
    "\n",
    "for subdir in os.listdir(base_dir):\n",
    "    if len(subdir) == 2: #all subdir lenghts in this dataset are 2 characters\n",
    "        for subsubdir in os.listdir(os.path.join(base_dir, subdir)):\n",
    "            if len(subsubdir) == 3: #all subdir lengths in this dataset are 3 characters\n",
    "                for file in os.listdir(os.path.join(base_dir, subdir, subsubdir)):\n",
    "                    if \".mat\" in file:\n",
    "                        files.append(os.path.join(base_dir, subdir, subsubdir, file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96a01f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_Dxs(file):\n",
    "    if \".mat\" in file:\n",
    "        file = file.replace(\".mat\", \".hea\")\n",
    "    elif \".hea\" not in file:\n",
    "        file += \".hea\"\n",
    "    \n",
    "    with open(file, \"r\") as f:\n",
    "        lines = f.readlines()\n",
    "    \n",
    "    for item in lines:\n",
    "        if \"#Dx\" in item:\n",
    "            Dxs = [dx.strip() for dx in item.split(\"Dx: \")[-1].split(',')]\n",
    "    return Dxs\n",
    "\n",
    "Dxs = [] #get set of dxs\n",
    "for i in tqdm(range(0, len(files))):\n",
    "    Dxs += extract_Dxs(files[i])\n",
    "Dxs = list(set(Dxs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4b70bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "labels = []\n",
    "\n",
    "for i in tqdm(range(0, len(files))):\n",
    "    raw = np.float32(scipy.io.loadmat(files[i])['val'])\n",
    "    \n",
    "    x = np.zeros((12, 1200))\n",
    "    \n",
    "    for channel in range(0, 12):\n",
    "        x[channel] = scipy.signal.resample(raw[channel], 1200)\n",
    "    \n",
    "    X.append(x)\n",
    "    labels.append(extract_Dxs(files[i]))\n",
    "\n",
    "X = np.float32(X)\n",
    "X = np.transpose(X.reshape(X.shape+(1,)), (0, 3, 1, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e80e3f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "MEANS = []\n",
    "STDEVS = []\n",
    "\n",
    "for i in tqdm(range(0, 12)):\n",
    "    MEANS.append(np.mean(X[:, :, i, :]))\n",
    "    STDEVS.append(np.std(X[:, :, i, :]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6de06be",
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in range(0, 12):\n",
    "    X[:, :, j, :] = (X[:, :, j, :] - MEANS[j]) / STDEVS[j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc02415a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in tqdm(range(0, len(X))):\n",
    "    for j in range(0, 12):\n",
    "        X[i, :, j, :] = butter_bandpass_filter(X[i, :, j, :], 0.55, 20, 120) # NOTE: this is not the final bandpass filter used in the paper, this was a preliminary filter used in the preprocess step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67797ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = labels\n",
    "classes = []\n",
    "for y in Y:\n",
    "    classes.extend(y)\n",
    "\n",
    "classes = list(set(classes))\n",
    "\n",
    "# convert labels to multi-hot encoding\n",
    "Y = np.array([np.array([1 if c in y else 0 for c in classes]) for y in Y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53e7ecc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"preprocessed_data.pkl\", \"wb\") as f:\n",
    "    pickle.dump({\"data\": X, \"labels\": Y, \"classes\": classes}, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
